{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "from pydataset import data\n",
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a spark data frame that contains your favorite programming languages.\n",
    "- The name of the column should be <code>language</code>\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language\n",
       "0         c++\n",
       "1  javascript\n",
       "2         PHP\n",
       "3      python\n",
       "4          go"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "programming2021 = pd.DataFrame(\n",
    "    {'language': ['c++', 'javascript', 'PHP', 'python', 'go']}\n",
    ")\n",
    "programming2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "programming = spark.createDataFrame(programming2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the schema\n",
    "\n",
    "programming.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "# output the shape\n",
    "\n",
    "print((programming.count(), len(programming.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|       c++|\n",
      "|javascript|\n",
      "|       PHP|\n",
      "|    python|\n",
      "|        go|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the first 5 reords\n",
    "\n",
    "programming.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the <code>mpg</code> dataset as a spark dataframe.\n",
    "- Create 1 column of output that contains a message like the one below: <br>\n",
    "    <code>The 1999 audi a4 has a 4 cylinder engine.</code> <br>\n",
    "    For each vehicle.\n",
    "- Transform the <code>trans</code> column so that it only contains either <code>manual</code> or <code>auto</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|             model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|                a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|                a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|                a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "|        audi|                a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "|        audi|                a4|  3.1|2008|  6|  auto(av)|  f| 18| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|manual(m5)|  4| 18| 26|  p|compact|\n",
      "|        audi|        a4 quattro|  1.8|1999|  4|  auto(l5)|  4| 16| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|manual(m6)|  4| 20| 28|  p|compact|\n",
      "|        audi|        a4 quattro|  2.0|2008|  4|  auto(s6)|  4| 19| 27|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  2.8|1999|  6|manual(m5)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|compact|\n",
      "|        audi|        a4 quattro|  3.1|2008|  6|manual(m6)|  4| 15| 25|  p|compact|\n",
      "|        audi|        a6 quattro|  2.8|1999|  6|  auto(l5)|  4| 15| 24|  p|midsize|\n",
      "|        audi|        a6 quattro|  3.1|2008|  6|  auto(s6)|  4| 17| 25|  p|midsize|\n",
      "|        audi|        a6 quattro|  4.2|2008|  8|  auto(s6)|  4| 16| 23|  p|midsize|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 14| 20|  r|    suv|\n",
      "|   chevrolet|c1500 suburban 2wd|  5.3|2008|  8|  auto(l4)|  r| 11| 15|  e|    suv|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg = spark.createDataFrame(data('mpg'))\n",
    "mpg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+\n",
      "|vehicle_cyl                                                  |\n",
      "+-------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 4cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 6cylinder engine.                     |\n",
      "|The 1999 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 1999 audi a6 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 8cylinder engine.             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8cylinder engine.|\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8cylinder engine.|\n",
      "+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "# The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "mpg.select(\n",
    "    concat(\n",
    "        lit('The '),\n",
    "        col('year'),\n",
    "        lit(' '),\n",
    "        col('manufacturer'),\n",
    "        lit(' '),\n",
    "        col('model'),\n",
    "        lit(' has a '),\n",
    "        col('cyl'),\n",
    "        lit('cylinder engine.')\n",
    "    ).alias('vehicle_cyl')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|     trans|when + like|\n",
      "+----------+-----------+\n",
      "|  auto(l5)|       auto|\n",
      "|manual(m5)|     manual|\n",
      "|manual(m6)|     manual|\n",
      "|  auto(av)|       auto|\n",
      "|  auto(l5)|       auto|\n",
      "|manual(m5)|     manual|\n",
      "|  auto(av)|       auto|\n",
      "|manual(m5)|     manual|\n",
      "|  auto(l5)|       auto|\n",
      "|manual(m6)|     manual|\n",
      "|  auto(s6)|       auto|\n",
      "|  auto(l5)|       auto|\n",
      "|manual(m5)|     manual|\n",
      "|  auto(s6)|       auto|\n",
      "|manual(m6)|     manual|\n",
      "|  auto(l5)|       auto|\n",
      "|  auto(s6)|       auto|\n",
      "|  auto(s6)|       auto|\n",
      "|  auto(l4)|       auto|\n",
      "|  auto(l4)|       auto|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "mpg.select(\n",
    "    'trans',\n",
    "    when(\n",
    "        mpg.trans.like(\"auto%\"), \"auto\"\n",
    "    ).otherwise(\"manual\").alias(\"when + like\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the <code>tips</code> dataset as a spark dataframe.\n",
    "- What percentage of observations are smokers?\n",
    "- Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tips as a spark dataframe\n",
    "\n",
    "tips = spark.createDataFrame(data('tips'))\n",
    "tips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what percentage of observations are smokers?\n",
    "# group by first\n",
    "\n",
    "tips.groupBy('smoker').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|smoker|count|percent|\n",
      "+------+-----+-------+\n",
      "|    No|  151|    62%|\n",
      "|   Yes|   93|    38%|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find percentage\n",
    "\n",
    "tips.groupBy(\"smoker\").count().withColumn(\n",
    "    \"percent\",\n",
    "    concat(round((col(\"count\") / tips.count() * 100), 0).cast(\"int\"), lit(\"%\")),\n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|     tip_percentage|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a column that shows the tip percentage.\n",
    "\n",
    "tips.withColumn('tip_percentage',col('tip') / col('total_bill')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|   sex|    No|   Yes|\n",
      "+------+------+------+\n",
      "|Female|0.1569|0.1822|\n",
      "|  Male|0.1607|0.1528|\n",
      "+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the average tip percentage for each combination of sex and smoker\n",
    "\n",
    "(\n",
    "    tips.withColumn('tip_percentage', col('tip') / col('total_bill'))\n",
    "    .groupby('sex')\n",
    "    .pivot('smoker')\n",
    "    .agg(round(mean('tip_percentage'), 4))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weather dataset\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean:\n",
      "water, Wheat, deaths, waders, Weimar, winter, watervoles, bcdeter, veteran, newpainters, Snow.deaths\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e8ca4c58b5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weather'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    673\u001b[0m             return super(SparkSession, self).createDataFrame(\n\u001b[1;32m    674\u001b[0m                 data, schema, samplingRatio, verifySchema)\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
